# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023, Xorbits Inc.
# This file is distributed under the same license as the Xinference package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2023.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Xinference \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-08-07 11:39+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: ja_JP\n"
"Language-Team: ja_JP <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.12.1\n"

#: ../../source/user_guide/examples/chat.rst:3
msgid "Example: chatbot ü§ñÔ∏è"
msgstr ""

#: ../../source/user_guide/examples/chat.rst:5
msgid "**Description**:"
msgstr ""

#: ../../source/user_guide/examples/chat.rst:7
msgid ""
"Demonstrate how to interact with Xinference to play with LLM chat "
"functionality with an AI agent üíª"
msgstr ""

#: ../../source/user_guide/examples/chat.rst:9
msgid "**Used Technology**:"
msgstr ""

#: ../../source/user_guide/examples/chat.rst:11
msgid ""
"@ `ggerganov <https://twitter.com/ggerganov>`_ 's `ggml "
"<https://github.com/ggerganov/ggml>`_"
msgstr ""

#: ../../source/user_guide/examples/chat.rst:13
msgid "@ `Xinference <https://github.com/xorbitsai/inference>`_ as a launcher"
msgstr ""

#: ../../source/user_guide/examples/chat.rst:15
msgid ""
"@ All LLaMA and Chatglm models supported by `Xorbitsio inference "
"<https://github.com/xorbitsai/inference>`_"
msgstr ""

#: ../../source/user_guide/examples/chat.rst:17
msgid "**Detailed Explanation on the Demo Functionality** :"
msgstr ""

#: ../../source/user_guide/examples/chat.rst:19
msgid ""
"Take the user command line input in the terminal and grab the required "
"parameters for model lanuching."
msgstr ""

#: ../../source/user_guide/examples/chat.rst:21
msgid ""
"Launch the Xinference frameworks and automatically deploy the model user "
"demanded into the cluster."
msgstr ""

#: ../../source/user_guide/examples/chat.rst:23
msgid "Initialize an empty chat history to store all the context in the chatroom."
msgstr ""

#: ../../source/user_guide/examples/chat.rst:25
msgid ""
"Recursively ask for user's input as prompt and let the model to generate "
"response based on the prompt and the chat history. Show the Output of the"
" response in the terminal."
msgstr ""

#: ../../source/user_guide/examples/chat.rst:28
msgid ""
"Store the user's input and agent's response into the chat history as "
"context for the upcoming rounds."
msgstr ""

#: ../../source/user_guide/examples/chat.rst:30
msgid "**Source Code** :"
msgstr ""

#: ../../source/user_guide/examples/chat.rst:31
msgid ""
"`chat "
"<https://github.com/RayJi01/Xprobe_inference/blob/main/examples/chat.py>`_"
msgstr ""

